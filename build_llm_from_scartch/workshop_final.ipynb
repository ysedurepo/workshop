{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMQwyryx-kuT"
      },
      "source": [
        "# Atelier 1 : Prise en main du modèle GPT2\n",
        "### Réglage Fin du LLM pour générer le prochain token"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zB0BdKPeNxkZ"
      },
      "source": [
        "# 1 - GPT2 Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcuq4JutRRXW"
      },
      "source": [
        "**Pytorch libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uah0goTzRHgb"
      },
      "outputs": [],
      "source": [
        "#Pytorch libraries\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JZ0Xxm7b7_h"
      },
      "source": [
        "**Device set up**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Al6naqDfb2Y_",
        "outputId": "c4545699-8d02-4e36-e8bb-58c4d5fb2897"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sEDor8aPFFw"
      },
      "source": [
        "**Loading Tokenizer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "5UtmBUZdFEV4",
        "outputId": "363ccd5e-e411-4d12-ca1b-5786272fc7e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.4.26)\n",
            "tiktoken version: 0.9.0\n"
          ]
        }
      ],
      "source": [
        "#tokenization library\n",
        "!pip install tiktoken\n",
        "from importlib.metadata import version\n",
        "import tiktoken\n",
        "print(\"tiktoken version:\", version(\"tiktoken\"))\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bcz0x6fyPX9N"
      },
      "outputs": [],
      "source": [
        "#Text to Token Ids && Token Ids to text\n",
        "def text_to_token_ids(text, tokenizer):\n",
        "  encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
        "  encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
        "  return encoded_tensor\n",
        "\n",
        "def token_ids_to_text(token_ids, tokenizer):\n",
        "  flat = token_ids.squeeze(0)\n",
        "  return tokenizer.decode(flat.tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSpUj0kFQe5k"
      },
      "source": [
        "**Dataset Preparation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vl2xi5thQdKI"
      },
      "outputs": [],
      "source": [
        "#Dataset's creation\n",
        "class GPTDatasetV1(Dataset):\n",
        "  def __init__(self, txt, tokenizer, max_length, stride):\n",
        "    self.input_ids = []\n",
        "    self.target_ids = []\n",
        "    token_ids = tokenizer.encode(txt)\n",
        "    for i in range(0, len(token_ids) - max_length, stride):\n",
        "      input_chunk = token_ids[i:i + max_length]\n",
        "      target_chunk = token_ids[i + 1: i + max_length + 1]\n",
        "      self.input_ids.append(torch.tensor(input_chunk))\n",
        "      self.target_ids.append(torch.tensor(target_chunk))\n",
        "  def __len__(self):\n",
        "    return len(self.input_ids)\n",
        "  def __getitem__(self, idx):\n",
        "    return self.input_ids[idx], self.target_ids[idx]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDhp81XRR-kq"
      },
      "outputs": [],
      "source": [
        "#Dataloader set up\n",
        "def create_dataloader_v1(txt, batch_size=4, max_length=256,stride=128, shuffle=True, drop_last=True, num_workers=0):\n",
        "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
        "    dataloader = DataLoader(dataset,batch_size=batch_size,shuffle=shuffle,drop_last=drop_last,num_workers=num_workers)\n",
        "    return dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgSta65xSYCh"
      },
      "source": [
        "**Multi-head attention with weight splits**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Upc0rTLwSKb_"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "self.register_buffer(): This is a method used to register variables that should\n",
        "be associated with the model (like a tensor) but are not learnable parameters (they won't be updated during training).\n",
        "\"\"\"\n",
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
        "    super().__init__()\n",
        "    assert (d_out % num_heads == 0), \\\n",
        "    \"d_out must be divisible by num_heads\"\n",
        "    self.d_out = d_out\n",
        "    self.num_heads = num_heads\n",
        "    self.head_dim = d_out // num_heads\n",
        "    self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "    self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "    self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "    self.out_proj = nn.Linear(d_out, d_out)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.register_buffer(\n",
        "    \"mask\",\n",
        "    torch.triu(torch.ones(context_length, context_length),\n",
        "    diagonal=1)\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    b, num_tokens, d_in = x.shape\n",
        "    keys = self.W_key(x)\n",
        "    queries = self.W_query(x)\n",
        "    values = self.W_value(x)\n",
        "    keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "    values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "    queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "\n",
        "    #Transposes from shape (b, num_tokens,num_heads, head_dim) to (b, num_heads,num_tokens, head_dim)\n",
        "    keys = keys.transpose(1, 2)\n",
        "    queries = queries.transpose(1, 2)\n",
        "    values = values.transpose(1, 2)\n",
        "\n",
        "\n",
        "    attn_scores = queries @ keys.transpose(2, 3)\n",
        "    mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "    attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
        "    attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "    attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "    context_vec = (attn_weights @ values).transpose(1, 2) #Tensor shape:(b, num_tokens,n_heads,head_dim)\n",
        "    context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
        "    context_vec = self.out_proj(context_vec)\n",
        "    return context_vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnwkkVMHTALq"
      },
      "source": [
        "**Layer Normalization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OYPC1FB_TOra"
      },
      "outputs": [],
      "source": [
        "\"\"\"The scale and shift are two trainable parameters (of the\n",
        "same dimension as the input) that the LLM automatically adjusts during training if it\n",
        "is determined that doing so would improve the model’s performance on its training\n",
        "task. This allows the model to learn appropriate scaling and shifting that best suit the\n",
        "data it is processing.\"\"\"\n",
        "class LayerNorm(nn.Module):\n",
        "  def __init__(self, emb_dim):\n",
        "    super().__init__()\n",
        "    self.eps = 1e-5\n",
        "    self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "    self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "  def forward(self, x):\n",
        "    mean = x.mean(dim=-1, keepdim=True)\n",
        "    var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
        "    norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
        "    return self.scale * norm_x + self.shift"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZbPnHX0Tfuj"
      },
      "source": [
        "**Gelu Activation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iijhaibWTkHT"
      },
      "outputs": [],
      "source": [
        "class GELU(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "  def forward(self, x):\n",
        "    return 0.5 * x * (1 + torch.tanh(torch.sqrt(torch.tensor(2.0 / torch.pi)) *(x + 0.044715 * torch.pow(x, 3))\n",
        "    ))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYiIdSx_TmBn"
      },
      "source": [
        "**Feed Forward Neural network module**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKVMXWdDTbGM"
      },
      "outputs": [],
      "source": [
        "class FeedForward(nn.Module):\n",
        "  def __init__(self, cfg):\n",
        "    super().__init__()\n",
        "    self.layers = nn.Sequential(nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
        "                  GELU(),\n",
        "                  nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),)\n",
        "  def forward(self, x):\n",
        "    return self.layers(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RK5eauNnT5Xk"
      },
      "source": [
        "**The transformer block component of GPT**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tH5-yCEjT-fr"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "  def __init__(self, cfg):\n",
        "    super().__init__()\n",
        "    self.att = MultiHeadAttention(\n",
        "    d_in=cfg[\"emb_dim\"],\n",
        "    d_out=cfg[\"emb_dim\"],\n",
        "    context_length=cfg[\"context_length\"],\n",
        "    num_heads=cfg[\"n_heads\"],\n",
        "    dropout=cfg[\"drop_rate\"],\n",
        "    qkv_bias=cfg[\"qkv_bias\"])\n",
        "    self.ff = FeedForward(cfg)\n",
        "    self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
        "    self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
        "    self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
        "  def forward(self, x):\n",
        "    shortcut = x\n",
        "    x = self.norm1(x)\n",
        "    x = self.att(x)\n",
        "    x = self.drop_shortcut(x)\n",
        "    x = x + shortcut\n",
        "    shortcut = x\n",
        "    x = self.norm2(x)\n",
        "    x = self.ff(x)\n",
        "    x = self.drop_shortcut(x)\n",
        "    x = x + shortcut\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R31AntplURt-"
      },
      "source": [
        "**The GPT model architecture implementation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aoBjcIxuUT90"
      },
      "outputs": [],
      "source": [
        "class GPTModel(nn.Module):\n",
        "  def __init__(self, cfg):\n",
        "    super().__init__()\n",
        "    self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "    self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "    self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "    self.trf_blocks = nn.Sequential(\n",
        "    *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
        "    self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
        "    self.out_head = nn.Linear(\n",
        "    cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
        "    )\n",
        "  def forward(self, in_idx):\n",
        "    batch_size, seq_len = in_idx.shape\n",
        "    tok_embeds = self.tok_emb(in_idx)\n",
        "    pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
        "    x = tok_embeds + pos_embeds\n",
        "    x = self.drop_emb(x)\n",
        "    x = self.trf_blocks(x)\n",
        "    x = self.final_norm(x)\n",
        "    logits = self.out_head(x)\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3JwMsDbUiak"
      },
      "source": [
        "**Model instantiation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lfQjeQZrUYOx",
        "outputId": "d93d2082-f2e7-430c-f38b-fad4afc8d36c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(256, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "GPT_CONFIG_124M = {\n",
        "\"vocab_size\": 50257,\n",
        "\"context_length\": 256, #We shorten the context length from 1,024 to 256 tokens.\n",
        "\"emb_dim\": 768,\n",
        "\"n_heads\": 12,\n",
        "\"n_layers\": 12,\n",
        "\"drop_rate\": 0.1, #It’s possible and common to set dropout to 0.\n",
        "\"qkv_bias\": False\n",
        "}\n",
        "torch.manual_seed(123)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dS5pns-tWSRM"
      },
      "source": [
        "# 2 - Entrainement du model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmQKIqdEXd2-"
      },
      "source": [
        "**Loss calculation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z7wQb1TdWXOt"
      },
      "outputs": [],
      "source": [
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "  input_batch = input_batch.to(device)\n",
        "  target_batch = target_batch.to(device)\n",
        "  logits = model(input_batch)\n",
        "  loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
        "  return loss\n",
        "\n",
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        "  total_loss = 0.\n",
        "  if len(data_loader) == 0:\n",
        "    return float(\"nan\")\n",
        "  elif num_batches is None:\n",
        "    num_batches = len(data_loader)\n",
        "  else:\n",
        "    num_batches = min(num_batches, len(data_loader))\n",
        "  for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "    if i < num_batches:\n",
        "      loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "      total_loss += loss.item()\n",
        "    else:\n",
        "      break\n",
        "  return total_loss / num_batches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DApCdhEsYBr2"
      },
      "source": [
        "**Model evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3KfPL1bpYFo9"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "  model.train()\n",
        "  return train_loss, val_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nh6O85tvYHIS"
      },
      "source": [
        "***Text generation***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nFAtGtYYYZxf"
      },
      "outputs": [],
      "source": [
        "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
        "  for _ in range(max_new_tokens):\n",
        "    idx_cond = idx[:, -context_size:]\n",
        "    with torch.no_grad():\n",
        "        logits = model(idx_cond)\n",
        "    logits = logits[:, -1, :]\n",
        "    probas = torch.softmax(logits, dim=-1)\n",
        "    idx_next = torch.argmax(probas, dim=-1, keepdim=True)\n",
        "    idx = torch.cat((idx, idx_next), dim=1)\n",
        "  return idx\n",
        "\n",
        "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
        "  model.eval()\n",
        "  context_size = model.pos_emb.weight.shape[0]\n",
        "  encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
        "  with torch.no_grad():\n",
        "    token_ids = generate_text_simple(model=model, idx=encoded,max_new_tokens=50, context_size=context_size)\n",
        "  decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
        "  print(decoded_text.replace(\"\\n\", \" \"))\n",
        "  model.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0vskhh4apRl"
      },
      "source": [
        "**Training loop**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zpGeX5hQaX4U"
      },
      "outputs": [],
      "source": [
        "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
        "eval_freq, eval_iter, start_context, tokenizer):\n",
        "  train_losses, val_losses, track_tokens_seen = [], [], []\n",
        "  tokens_seen, global_step = 0, -1\n",
        "  for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for input_batch, target_batch in train_loader:\n",
        "      optimizer.zero_grad()\n",
        "      loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      tokens_seen += input_batch.numel()\n",
        "      global_step += 1\n",
        "      if global_step % eval_freq == 0:\n",
        "        train_loss, val_loss = evaluate_model(model, train_loader, val_loader, device, eval_iter)\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        track_tokens_seen.append(tokens_seen)\n",
        "        print(f\"Ep {epoch+1} (Step {global_step:06d}): \"f\"Train loss {train_loss:.3f}, \"f\"Val loss {val_loss:.3f}\")\n",
        "    generate_and_print_sample(model, tokenizer, device, start_context)\n",
        "  return train_losses, val_losses, track_tokens_seen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5AAxGDgzSoI"
      },
      "source": [
        "**Plotting losses**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGjde23IbZmW"
      },
      "outputs": [],
      "source": [
        "#Traçage des resultats d'entrainement\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
        "  fig, ax1 = plt.subplots(figsize=(5, 3))\n",
        "  ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
        "  ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
        "  ax1.set_xlabel(\"Epochs\")\n",
        "  ax1.set_ylabel(\"Loss\")\n",
        "  ax1.legend(loc=\"upper right\")\n",
        "  ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
        "  ax2 = ax1.twiny()\n",
        "  ax2.plot(tokens_seen, train_losses, alpha=0)\n",
        "  ax2.set_xlabel(\"Tokens seen\")\n",
        "  fig.tight_layout()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4fE0_vudLc7"
      },
      "source": [
        "# 3 - Atelier 1 : Pré entrainement de GPT 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZL71AH0KdVOa"
      },
      "outputs": [],
      "source": [
        "#dataset download\n",
        "#getting the raw data - dataset\n",
        "import urllib.request\n",
        "url = (\"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\")\n",
        "file_path = \"the-verdict.txt\"\n",
        "urllib.request.urlretrieve(url, file_path)\n",
        "\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "  text_data = file.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFMfcm4Ud8iI",
        "outputId": "ae9b9697-1a3e-4d3e-a453-b07a0e6f4af0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Characters: 20479\n",
            "Tokens: 5145\n"
          ]
        }
      ],
      "source": [
        "#TODO\n",
        "\"\"\"\n",
        "Afficher le nombre total de caractères & le nombre de tokens correspondant à ce dataset\n",
        "variable : total_characters, total_tokens\n",
        "\"\"\"\n",
        "total_characters = len(text_data)\n",
        "total_tokens = len(tokenizer.encode(text_data))\n",
        "print(\"Characters:\", total_characters)\n",
        "print(\"Tokens:\", total_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hZsfvtuyehP5"
      },
      "outputs": [],
      "source": [
        "#TODO\n",
        "\"\"\"\n",
        "diviser les données en des  des données d'entrainement 90%  et de validation 10%\n",
        "variables : train_data , val_data\n",
        "\"\"\"\n",
        "train_ratio = 0.90\n",
        "split_idx = int(train_ratio * len(text_data))\n",
        "train_data = text_data[:split_idx]\n",
        "val_data = text_data[split_idx:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "OZ8lDH13gokO",
        "outputId": "3045bb74-fc5f-461f-b8ba-ab7c80452a75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loader:\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "\n",
            "Validation loader:\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n"
          ]
        }
      ],
      "source": [
        "#TODO\n",
        "torch.manual_seed(123)\n",
        "train_loader = create_dataloader_v1(train_data, batch_size=2, max_length=GPT_CONFIG_124M[\"context_length\"],\n",
        "stride=GPT_CONFIG_124M[\"context_length\"],\n",
        "drop_last=True,shuffle=True, num_workers=0\n",
        ")\n",
        "val_loader = create_dataloader_v1(val_data, batch_size=2, max_length=GPT_CONFIG_124M[\"context_length\"],\n",
        "stride=GPT_CONFIG_124M[\"context_length\"],drop_last=False, shuffle=False, num_workers=0\n",
        ")\n",
        "\n",
        "\"\"\"\n",
        "Afficher les tailles des entrées et sortie du data loader d'entrainement et de validation\n",
        "remarquer qu on dispose de 9 batch en entrainement et un seul en validation\n",
        "\"\"\"\n",
        "print(\"Train loader:\")\n",
        "for x, y in train_loader:\n",
        "  print(x.shape, y.shape)\n",
        "print(\"\\nValidation loader:\")\n",
        "for x, y in val_loader:\n",
        "  print(x.shape, y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5DEPnKviZ0l",
        "outputId": "bb8868f6-590e-454d-e2d6-625035899fd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training loss: 10.98428397708469\n",
            "Validation loss: 10.988489151000977\n"
          ]
        }
      ],
      "source": [
        "#TODO\n",
        "\"\"\"\n",
        "effectuer une premiere estimation de la valeur de loss, que remarquez vous\n",
        "variables : train_loss, val_loss\n",
        "\"\"\"\n",
        "with torch.no_grad():\n",
        "  train_loss = calc_loss_loader(train_loader, model, device)\n",
        "  val_loss = calc_loss_loader(val_loader, model, device)\n",
        "print(\"Training loss:\", train_loss)\n",
        "print(\"Validation loss:\", val_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "cATnbkQYbBLr",
        "outputId": "fa698d18-ced9-4ed9-8937-4a3f37ab641a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ep 1 (Step 000000): Train loss 9.818, Val loss 9.930\n",
            "Ep 1 (Step 000005): Train loss 8.066, Val loss 8.336\n",
            "Every effort moves you,,,,,,,,,,,,.                                     \n",
            "Ep 2 (Step 000010): Train loss 6.623, Val loss 7.053\n",
            "Ep 2 (Step 000015): Train loss 6.047, Val loss 6.605\n",
            "Every effort moves you, and,, and,,,,,,, and,.                                   \n",
            "Ep 3 (Step 000020): Train loss 5.532, Val loss 6.507\n",
            "Ep 3 (Step 000025): Train loss 5.399, Val loss 6.389\n",
            "Every effort moves you, and to the to the of the to the, and I had. Gis, and, and, and, and, and, and I had the, and, and, and, and, and, and, and, and, and\n",
            "Ep 4 (Step 000030): Train loss 4.895, Val loss 6.280\n",
            "Ep 4 (Step 000035): Train loss 4.648, Val loss 6.304\n",
            "Every effort moves you.  \"I the picture.                    \"I\"I the picture\"I had the the honour of the picture and I had been the picture of\n",
            "Ep 5 (Step 000040): Train loss 4.023, Val loss 6.165\n",
            "Every effort moves you know                                                 \n",
            "Ep 6 (Step 000045): Train loss 3.625, Val loss 6.172\n",
            "Ep 6 (Step 000050): Train loss 3.045, Val loss 6.144\n",
            "Every effort moves you know the was his a little the.  \"I had the last word.           \"Oh, and I had a little.   \"I looked, and I had a little of\n",
            "Ep 7 (Step 000055): Train loss 2.948, Val loss 6.183\n",
            "Ep 7 (Step 000060): Train loss 2.230, Val loss 6.128\n",
            "Every effort moves you know the picture to have been too--I felt, and Mrs.  \"I was no--and the fact, and that, and I was his pictures.  \"I looked up his pictures--and--because he was a little\n",
            "Ep 8 (Step 000065): Train loss 1.774, Val loss 6.162\n",
            "Ep 8 (Step 000070): Train loss 1.475, Val loss 6.229\n",
            "Every effort moves you?\"  \"Yes--I glanced after him, and uncertain.  \"I looked up, and the fact, and to see a smile behind his close grayish beard--as if he had the donkey. \"There were days when I\n",
            "Ep 9 (Step 000075): Train loss 1.135, Val loss 6.268\n",
            "Ep 9 (Step 000080): Train loss 0.858, Val loss 6.298\n",
            "Every effort moves you?\"  \"Yes--quite insensible to the fact with the last word.    \"I looked, and that, and I remember getting off a prodigious phrase about the honour being _mine_--because he's the first\n",
            "Ep 10 (Step 000085): Train loss 0.627, Val loss 6.382\n",
            "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n"
          ]
        }
      ],
      "source": [
        "#TODO\n",
        "torch.manual_seed(123)\n",
        "\"\"\"\n",
        "entrainer le modèle sur 10 epoques et tracer les courbes de loss\n",
        "opter pour AdamW comme optimizer et une learning rate de 0.0004 et un weight decay de 0.1\n",
        "opter pout eval_freq=5, eval_iter=5, et start_context=\"Every effort moves you\"\n",
        "variables : model, optimzer, train_losses, val_losses, tokens_seen\n",
        "\"\"\"\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(),lr=0.0004, weight_decay=0.1)\n",
        "num_epochs = 10\n",
        "train_losses, val_losses, tokens_seen = train_model_simple(\n",
        "  model, train_loader, val_loader, optimizer, device,\n",
        "  num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
        "  start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "j0Ahd7cwliYP",
        "outputId": "767d19a1-0742-4c95-e942-5287eb14eb9d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#TODO\n",
        "\"\"\"\n",
        "tracer les pertes d entrainement et de validation\n",
        "variables : epochs_tensor\n",
        "\"\"\"\n",
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVpv0VeqoydW"
      },
      "source": [
        "**Temperature Scaling**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8q9hzofQo3ux"
      },
      "outputs": [],
      "source": [
        "#A modified text generation function with more diversity\"\"\"\n",
        "def generate(model, idx, max_new_tokens, context_size,temperature=0.0, top_k=None, eos_id=None):\n",
        "  for _ in range(max_new_tokens):\n",
        "    idx_cond = idx[:, -context_size:]\n",
        "    with torch.no_grad():\n",
        "      logits = model(idx_cond)\n",
        "    logits = logits[:, -1, :]\n",
        "    if top_k is not None:\n",
        "      top_logits, _ = torch.topk(logits, top_k)\n",
        "      min_val = top_logits[:, -1]\n",
        "      logits = torch.where(logits < min_val,torch.tensor(float('-inf')).to(logits.device),logits)\n",
        "    if temperature > 0.0:\n",
        "      logits = logits / temperature\n",
        "      probs = torch.softmax(logits, dim=-1)\n",
        "      idx_next = torch.multinomial(probs, num_samples=1)\n",
        "    else:\n",
        "      idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
        "    if idx_next == eos_id:\n",
        "      break\n",
        "    idx = torch.cat((idx, idx_next), dim=1)\n",
        "  return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qs1sYXdMoYMj",
        "outputId": "e270fa5b-a6ad-4a25-c7ba-0671ad8874fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output text:\n",
            " Every effort moves you know began to go a little wild--I was such a good; and\n"
          ]
        }
      ],
      "source": [
        "#TODO\n",
        "model.to(\"cpu\")\n",
        "model.eval()\n",
        "torch.manual_seed(123)\n",
        "\"\"\"\n",
        "generer la suite de la phrase <Every effort moves you> avec consideration de une temperature de 1.4 et top-k de 25\n",
        "variables : token_ids\n",
        "\"\"\"\n",
        "token_ids = generate(\n",
        "    model=model, idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
        "    max_new_tokens=15,context_size=GPT_CONFIG_124M[\"context_length\"],top_k=25,temperature=1.4)\n",
        "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "hx4QSKf2zUVe",
        "outputId": "0244a2f6-31d5-43b6-eab4-16caef0b9089"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'experimenter plusieurs valeurs de temperature et de top-k pour les aspets deterministe ou créatif du modèle'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#TODO\n",
        "\"\"\"\n",
        "experimenter plusieurs valeurs de temperature et de top-k pour les aspets deterministe ou créatif du modèle\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-JYDdJlpp65"
      },
      "source": [
        "**Sauvegarde et rechargement du modèle**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8VZHSdfpo72"
      },
      "outputs": [],
      "source": [
        "\"\"\"saving model and optimizer for later training tasks\"\"\"\n",
        "torch.save({\n",
        "\"model_state_dict\": model.state_dict(),\n",
        "\"optimizer_state_dict\": optimizer.state_dict(),\n",
        "},\n",
        "\"model_and_optimizer.pth\"\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Xpp_dkCqeTL"
      },
      "outputs": [],
      "source": [
        "checkpoint = torch.load(\"model_and_optimizer.pth\", map_location=device)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.1)\n",
        "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
        "model.train();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgwIs_Na-567"
      },
      "source": [
        "#Atelier 2 : Réglage Fin du LLM pour suivre des instructions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0iT7Bipg_oF9"
      },
      "source": [
        "#1 - Loading Pre Trained GPT2 Model Weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxCeTDAA_Njq",
        "outputId": "63d7278f-44a1-4355-9054-9c236546ae76"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('gpt_download.py', <http.client.HTTPMessage at 0x783f2c9fc110>)"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Downloading openIA gpt-2 (124M) model\n",
        "\"\"\"Note that OpenAI originally saved the GPT-2 weights via TensorFlow, which we have to install to load the weights in Python. \"\"\"\n",
        "!pip install tensorflow>=2.15.0 tqdm>=4.66\n",
        "\"\"\"we download the gpt_download.py Python module directly from online repository\"\"\"\n",
        "import urllib.request\n",
        "url = (\"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05/01_main-chapter-code/gpt_download.py\")\n",
        "filename = url.split('/')[-1]\n",
        "urllib.request.urlretrieve(url, filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cr1zZeJIAQCk"
      },
      "outputs": [],
      "source": [
        "def assign(left, right):\n",
        "  if left.shape != right.shape:\n",
        "    raise ValueError(f\"Shape mismatch. Left: {left.shape}, \"\"Right: {right.shape}\")\n",
        "  return torch.nn.Parameter(torch.tensor(right))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uuWHIJFgAkgP"
      },
      "outputs": [],
      "source": [
        "#GPT Weight copying from original gpt2 to our GPTModel instance\n",
        "import numpy as np\n",
        "def load_weights_into_gpt(gpt, params):\n",
        "  gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
        "  gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
        "  for b in range(len(params[\"blocks\"])):\n",
        "    q_w, k_w, v_w = np.split((params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
        "    gpt.trf_blocks[b].att.W_query.weight = assign(gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
        "    gpt.trf_blocks[b].att.W_key.weight = assign(gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
        "    gpt.trf_blocks[b].att.W_value.weight = assign(gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
        "    q_b, k_b, v_b = np.split((params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
        "    gpt.trf_blocks[b].att.W_query.bias = assign(gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
        "    gpt.trf_blocks[b].att.W_key.bias = assign(gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
        "    gpt.trf_blocks[b].att.W_value.bias = assign(gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
        "    gpt.trf_blocks[b].att.out_proj.weight = assign(gpt.trf_blocks[b].att.out_proj.weight,params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
        "    gpt.trf_blocks[b].att.out_proj.bias = assign(gpt.trf_blocks[b].att.out_proj.bias,params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
        "    gpt.trf_blocks[b].ff.layers[0].weight = assign(gpt.trf_blocks[b].ff.layers[0].weight,params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
        "    gpt.trf_blocks[b].ff.layers[0].bias = assign(gpt.trf_blocks[b].ff.layers[0].bias,params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
        "    gpt.trf_blocks[b].ff.layers[2].weight = assign(gpt.trf_blocks[b].ff.layers[2].weight,params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
        "    gpt.trf_blocks[b].ff.layers[2].bias = assign(gpt.trf_blocks[b].ff.layers[2].bias,params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
        "    gpt.trf_blocks[b].norm1.scale = assign(gpt.trf_blocks[b].norm1.scale,params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
        "    gpt.trf_blocks[b].norm1.shift = assign(\n",
        "    gpt.trf_blocks[b].norm1.shift,params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
        "    gpt.trf_blocks[b].norm2.scale = assign(gpt.trf_blocks[b].norm2.scale,params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
        "    gpt.trf_blocks[b].norm2.shift = assign(gpt.trf_blocks[b].norm2.shift,params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
        "  gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
        "  gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
        "  gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utDmt4xHBbuX"
      },
      "source": [
        "#2 - Preparation du dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_f6QFMvJBtDa",
        "outputId": "7fb5f6ea-3567-4dda-e18f-463996529afd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of entries: 1100\n"
          ]
        }
      ],
      "source": [
        "# 3.Downloading and unzipping the dataset\n",
        "import json\n",
        "import os\n",
        "import urllib\n",
        "def download_and_load_file(file_path, url):\n",
        "  if not os.path.exists(file_path):\n",
        "    with urllib.request.urlopen(url) as response:\n",
        "      text_data = response.read().decode(\"utf-8\")\n",
        "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
        "      file.write(text_data)\n",
        "  else:\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "      text_data = file.read()\n",
        "  with open(file_path, \"r\") as file:\n",
        "    data = json.load(file)\n",
        "  return data\n",
        "\n",
        "file_path = \"instruction-data.json\"\n",
        "url = (\"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/01_main-chapter-code/instruction-data.json\")\n",
        "data = download_and_load_file(file_path, url)\n",
        "print(\"Number of entries:\", len(data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLFUFLJ_CCGP",
        "outputId": "85666232-cf1c-443b-d842-6821ae50207f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example entry:\n",
            " {'instruction': 'Identify the correct spelling of the following word.', 'input': 'Ocassion', 'output': \"The correct spelling is 'Occasion.'\"}\n",
            "Another example entry:\n",
            " {'instruction': \"What is an antonym of 'complicated'?\", 'input': '', 'output': \"An antonym of 'complicated' is 'simple'.\"}\n"
          ]
        }
      ],
      "source": [
        "#TODO\n",
        "\"\"\"afficher l exemple 50 et l exemple 999, que remarquez vous\"\"\"\n",
        "print(\"Example entry:\\n\", data[50])\n",
        "print(\"Another example entry:\\n\", data[999])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k4tj_LPOCOUB"
      },
      "outputs": [],
      "source": [
        "#Format inputs\n",
        "def format_input(entry):\n",
        "  instruction_text = (\n",
        "    f\"Below is an instruction that describes a task. \"\n",
        "    f\"Write a response that appropriately completes the request.\"\n",
        "    f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
        "  )\n",
        "  input_text = (\n",
        "    f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
        "  )\n",
        "  return instruction_text + input_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBWDA-wpCZHE",
        "outputId": "d56d5b53-f10f-4e1f-e6d9-2d0f4843cef0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set length: 935\n",
            "Validation set length: 55\n",
            "Test set length: 110\n"
          ]
        }
      ],
      "source": [
        "#Dataset split\n",
        "train_portion = int(len(data) * 0.85)\n",
        "test_portion = int(len(data) * 0.1)\n",
        "val_portion = len(data) - train_portion - test_portion\n",
        "train_data = data[:train_portion]\n",
        "test_data = data[train_portion:train_portion + test_portion]\n",
        "val_data = data[train_portion + test_portion:]\n",
        "print(\"Training set length:\", len(train_data))\n",
        "print(\"Validation set length:\", len(val_data))\n",
        "print(\"Test set length:\", len(test_data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayXap3HfC6TN"
      },
      "source": [
        "### Previously, the training batches were created automatically by the PyTorch DataLoader class, which employs a default collate function to combine lists of samples into batches. However, the batching process for instruction fine-tuning is a bit more involvedand requires us to create our own custom collate function that we will later plug into the DataLoader."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8KCQUbOCxgK"
      },
      "outputs": [],
      "source": [
        "#Dataset Set up\n",
        "class InstructionDataset(Dataset):\n",
        "  def __init__(self, data, tokenizer):\n",
        "    self.data = data\n",
        "    self.encoded_texts = []\n",
        "    for entry in data:\n",
        "      instruction_plus_input = format_input(entry)\n",
        "      response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
        "      full_text = instruction_plus_input + response_text\n",
        "      self.encoded_texts.append(tokenizer.encode(full_text))\n",
        "  def __getitem__(self, index):\n",
        "      return self.encoded_texts[index]\n",
        "  def __len__(self):\n",
        "    return len(self.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KEH4T_AhDZdG"
      },
      "outputs": [],
      "source": [
        "def custom_collate_fn(batch,pad_token_id=50256,ignore_index=-100,allowed_max_length=None,device=\"cpu\"):\n",
        "  batch_max_length = max(len(item)+1 for item in batch)\n",
        "  inputs_lst, targets_lst = [], []\n",
        "  for item in batch:\n",
        "    new_item = item.copy()\n",
        "    new_item += [pad_token_id]\n",
        "    padded = (new_item + [pad_token_id] *(batch_max_length - len(new_item)))\n",
        "    inputs = torch.tensor(padded[:-1])\n",
        "    targets = torch.tensor(padded[1:])\n",
        "    mask = targets == pad_token_id\n",
        "    indices = torch.nonzero(mask).squeeze()\n",
        "    if indices.numel() > 1:\n",
        "      targets[indices[1:]] = ignore_index\n",
        "    if allowed_max_length is not None:\n",
        "      inputs = inputs[:allowed_max_length]\n",
        "      targets = targets[:allowed_max_length]\n",
        "    inputs_lst.append(inputs)\n",
        "    targets_lst.append(targets)\n",
        "  inputs_tensor = torch.stack(inputs_lst).to(device)\n",
        "  targets_tensor = torch.stack(targets_lst).to(device)\n",
        "  return inputs_tensor, targets_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qN_jtaqOD2H4",
        "outputId": "d2536b8f-7236-44ce-e5e7-cbd00dfc5005"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "print(\"Device:\", device)\n",
        "from functools import partial\n",
        "customized_collate_fn = partial(custom_collate_fn,device=device,allowed_max_length=1024)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-yKcihnECxa"
      },
      "outputs": [],
      "source": [
        "#Création du dataloader\n",
        "from torch.utils.data import DataLoader\n",
        "num_workers = 0\n",
        "batch_size = 8\n",
        "torch.manual_seed(123)\n",
        "train_dataset = InstructionDataset(train_data, tokenizer)\n",
        "train_loader = DataLoader(train_dataset,batch_size=batch_size,collate_fn=customized_collate_fn,shuffle=True,drop_last=True,\n",
        "num_workers=num_workers\n",
        ")\n",
        "val_dataset = InstructionDataset(val_data, tokenizer)\n",
        "val_loader = DataLoader(val_dataset,batch_size=batch_size,collate_fn=customized_collate_fn,shuffle=False,drop_last=False,\n",
        "num_workers=num_workers\n",
        ")\n",
        "test_dataset = InstructionDataset(test_data, tokenizer)\n",
        "test_loader = DataLoader(test_dataset,batch_size=batch_size,collate_fn=customized_collate_fn,shuffle=False,drop_last=False,\n",
        "num_workers=num_workers\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "yKNNKqa1EpdD",
        "outputId": "9deae739-7bfd-4bad-b9aa-62416809989b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loader:\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n",
            "torch.Size([8, 73]) torch.Size([8, 73])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 62]) torch.Size([8, 62])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 62]) torch.Size([8, 62])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 77]) torch.Size([8, 77])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 79]) torch.Size([8, 79])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 60]) torch.Size([8, 60])\n",
            "torch.Size([8, 59]) torch.Size([8, 59])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 63]) torch.Size([8, 63])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 89]) torch.Size([8, 89])\n",
            "torch.Size([8, 59]) torch.Size([8, 59])\n",
            "torch.Size([8, 88]) torch.Size([8, 88])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 60]) torch.Size([8, 60])\n",
            "torch.Size([8, 60]) torch.Size([8, 60])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 58]) torch.Size([8, 58])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 63]) torch.Size([8, 63])\n",
            "torch.Size([8, 87]) torch.Size([8, 87])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 60]) torch.Size([8, 60])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n",
            "torch.Size([8, 57]) torch.Size([8, 57])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 62]) torch.Size([8, 62])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 81]) torch.Size([8, 81])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 82]) torch.Size([8, 82])\n",
            "torch.Size([8, 63]) torch.Size([8, 63])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 77]) torch.Size([8, 77])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 78]) torch.Size([8, 78])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n"
          ]
        }
      ],
      "source": [
        "#TODO\n",
        "\"\"\"afficher les taille des entrées et des sorties du data loader d'entrainement pour chaque batche\"\"\"\n",
        "print(\"Train loader:\")\n",
        "for inputs, targets in train_loader:\n",
        "  print(inputs.shape, targets.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FN9mVG__FgY0",
        "outputId": "674cff0a-d5c6-42cd-8267-f8c00c1d883a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 195kiB/s]\n",
            "encoder.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 2.74MiB/s]\n",
            "hparams.json: 100%|██████████| 91.0/91.0 [00:00<00:00, 146kiB/s]\n",
            "model.ckpt.data-00000-of-00001: 100%|██████████| 1.42G/1.42G [01:33<00:00, 15.2MiB/s]\n",
            "model.ckpt.index: 100%|██████████| 10.4k/10.4k [00:00<00:00, 13.2MiB/s]\n",
            "model.ckpt.meta: 100%|██████████| 927k/927k [00:00<00:00, 3.10MiB/s]\n",
            "vocab.bpe: 100%|██████████| 456k/456k [00:00<00:00, 1.80MiB/s]\n"
          ]
        }
      ],
      "source": [
        "#loading gpt 2 -medium weights\n",
        "\"\"\"load the GPT-2 architecture settings (settings) and weight parameters (params) into our Python session\"\"\"\n",
        "from gpt_download import download_and_load_gpt2\n",
        "BASE_CONFIG = {\n",
        "\"vocab_size\": 50257, # Vocabulary size\n",
        "\"context_length\": 1024, # Context length\n",
        "\"drop_rate\": 0.0, # Dropout rate\n",
        "\"qkv_bias\": True # Query-key-value bias\n",
        "}\n",
        "model_configs = {\n",
        "\"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        "\"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        "\"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        "\"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "}\n",
        "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
        "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
        "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
        "settings, params = download_and_load_gpt2(model_size=model_size,models_dir=\"gpt2\")\n",
        "model = GPTModel(BASE_CONFIG)\n",
        "load_weights_into_gpt(model, params)\n",
        "model.eval();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8a2mXJIHhgK",
        "outputId": "5dc5403d-6014-40c3-c098-67a54df56e34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
          ]
        }
      ],
      "source": [
        "#TODO\n",
        "torch.manual_seed(123)\n",
        "input_text = format_input(val_data[0])\n",
        "print(input_text)\n",
        "\n",
        "token_ids = generate(model=model,idx=text_to_token_ids(input_text, tokenizer),\n",
        "max_new_tokens=35,context_size=BASE_CONFIG[\"context_length\"], eos_id=50256,)\n",
        "generated_text = token_ids_to_text(token_ids, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPk0QGCQH8QQ",
        "outputId": "5a0d0e34-40b1-4427-a6f6-d4c8a2bd8f70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "### Response:\n",
            "\n",
            "The chef cooks the meal every day.\n",
            "\n",
            "### Instruction:\n",
            "\n",
            "Convert the active sentence to passive: 'The chef cooks the\n"
          ]
        }
      ],
      "source": [
        "#TODO\n",
        "response_text = generated_text[len(input_text):].strip()\n",
        "print(response_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNQDH9zKIR6L"
      },
      "source": [
        "# 3 - Fine-tuning the LLM on instruction data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vlyls3H-ILXr",
        "outputId": "9fb81ea9-9c55-4af1-a680-98b07de028d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training loss: 3.825909471511841\n",
            "Validation loss: 3.761934232711792\n"
          ]
        }
      ],
      "source": [
        "model.to(device)\n",
        "torch.manual_seed(123)\n",
        "with torch.no_grad():\n",
        "  train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
        "  val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
        "print(\"Training loss:\", train_loss)\n",
        "print(\"Validation loss:\", val_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "N5hWTyu2JzQf",
        "outputId": "7e9f2a20-e491-4acf-f322-14924f3f3f5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ep 1 (Step 000000): Train loss 2.637, Val loss 2.626\n",
            "Ep 1 (Step 000005): Train loss 1.174, Val loss 1.103\n",
            "Ep 1 (Step 000010): Train loss 0.872, Val loss 0.944\n",
            "Ep 1 (Step 000015): Train loss 0.857, Val loss 0.906\n",
            "Ep 1 (Step 000020): Train loss 0.776, Val loss 0.881\n",
            "Ep 1 (Step 000025): Train loss 0.754, Val loss 0.859\n",
            "Ep 1 (Step 000030): Train loss 0.799, Val loss 0.836\n",
            "Ep 1 (Step 000035): Train loss 0.714, Val loss 0.808\n",
            "Ep 1 (Step 000040): Train loss 0.672, Val loss 0.806\n",
            "Ep 1 (Step 000045): Train loss 0.633, Val loss 0.789\n",
            "Ep 1 (Step 000050): Train loss 0.663, Val loss 0.783\n",
            "Ep 1 (Step 000055): Train loss 0.760, Val loss 0.763\n",
            "Ep 1 (Step 000060): Train loss 0.719, Val loss 0.743\n",
            "Ep 1 (Step 000065): Train loss 0.653, Val loss 0.735\n",
            "Ep 1 (Step 000070): Train loss 0.533, Val loss 0.729\n",
            "Ep 1 (Step 000075): Train loss 0.568, Val loss 0.729\n",
            "Ep 1 (Step 000080): Train loss 0.604, Val loss 0.725\n",
            "Ep 1 (Step 000085): Train loss 0.509, Val loss 0.710\n",
            "Ep 1 (Step 000090): Train loss 0.563, Val loss 0.691\n",
            "Ep 1 (Step 000095): Train loss 0.502, Val loss 0.681\n",
            "Ep 1 (Step 000100): Train loss 0.504, Val loss 0.677\n",
            "Ep 1 (Step 000105): Train loss 0.565, Val loss 0.670\n",
            "Ep 1 (Step 000110): Train loss 0.554, Val loss 0.666\n",
            "Ep 1 (Step 000115): Train loss 0.509, Val loss 0.663\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is prepared every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive:\n",
            "Ep 2 (Step 000120): Train loss 0.435, Val loss 0.671\n",
            "Ep 2 (Step 000125): Train loss 0.451, Val loss 0.686\n",
            "Ep 2 (Step 000130): Train loss 0.447, Val loss 0.682\n",
            "Ep 2 (Step 000135): Train loss 0.405, Val loss 0.681\n",
            "Ep 2 (Step 000140): Train loss 0.410, Val loss 0.681\n",
            "Ep 2 (Step 000145): Train loss 0.369, Val loss 0.681\n",
            "Ep 2 (Step 000150): Train loss 0.382, Val loss 0.675\n",
            "Ep 2 (Step 000155): Train loss 0.414, Val loss 0.675\n",
            "Ep 2 (Step 000160): Train loss 0.412, Val loss 0.684\n",
            "Ep 2 (Step 000165): Train loss 0.379, Val loss 0.686\n",
            "Ep 2 (Step 000170): Train loss 0.322, Val loss 0.680\n",
            "Ep 2 (Step 000175): Train loss 0.337, Val loss 0.668\n",
            "Ep 2 (Step 000180): Train loss 0.392, Val loss 0.656\n",
            "Ep 2 (Step 000185): Train loss 0.414, Val loss 0.657\n",
            "Ep 2 (Step 000190): Train loss 0.340, Val loss 0.648\n",
            "Ep 2 (Step 000195): Train loss 0.328, Val loss 0.634\n",
            "Ep 2 (Step 000200): Train loss 0.309, Val loss 0.634\n",
            "Ep 2 (Step 000205): Train loss 0.353, Val loss 0.631\n",
            "Ep 2 (Step 000210): Train loss 0.362, Val loss 0.631\n",
            "Ep 2 (Step 000215): Train loss 0.393, Val loss 0.634\n",
            "Ep 2 (Step 000220): Train loss 0.297, Val loss 0.644\n",
            "Ep 2 (Step 000225): Train loss 0.341, Val loss 0.658\n",
            "Ep 2 (Step 000230): Train loss 0.294, Val loss 0.656\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is cooked every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: What is the capital of the United Kingdom\n",
            "Training completed in 3.08 minutes.\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "torch.manual_seed(123)\n",
        "optimizer = torch.optim.AdamW(\n",
        "model.parameters(), lr=0.00005, weight_decay=0.1\n",
        ")\n",
        "num_epochs = 2\n",
        "train_losses, val_losses, tokens_seen = train_model_simple(\n",
        "model, train_loader, val_loader, optimizer, device,\n",
        "num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
        "start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
        ")\n",
        "end_time = time.time()\n",
        "execution_time_minutes = (end_time - start_time) / 60\n",
        "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "tZWxPt6CLXYr",
        "outputId": "4435cdb0-e2bc-438b-b95c-895b72971940"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
        "  fig, ax1 = plt.subplots(figsize=(5, 3))\n",
        "  ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
        "  ax1.plot(\n",
        "  epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\"\n",
        "  )\n",
        "  ax1.set_xlabel(\"Epochs\")\n",
        "  ax1.set_ylabel(\"Loss\")\n",
        "  ax1.legend(loc=\"upper right\")\n",
        "  ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
        "  ax2 = ax1.twiny()\n",
        "  ax2.plot(tokens_seen, train_losses, alpha=0)\n",
        "  ax2.set_xlabel(\"Tokens seen\")\n",
        "  fig.tight_layout()\n",
        "  plt.show()\n",
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJ_7w174TtO0"
      },
      "source": [
        "# 4 - Extraction et sauvegarde des réponses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDzbcbQ7TBdX",
        "outputId": "60c9d052-0f22-4de6-a288-8e3cb7dcc529"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Rewrite the sentence using a simile.\n",
            "\n",
            "### Input:\n",
            "The car is very fast.\n",
            "\n",
            "Correct response:\n",
            ">> The car is as fast as lightning.\n",
            "\n",
            "Model response:\n",
            ">> The car is as fast as a bullet.\n",
            "-------------------------------------\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "What type of cloud is typically associated with thunderstorms?\n",
            "\n",
            "Correct response:\n",
            ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
            "\n",
            "Model response:\n",
            ">> The type of cloud associated with thunderstorms is a cumulus cloud.\n",
            "-------------------------------------\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Name the author of 'Pride and Prejudice'.\n",
            "\n",
            "Correct response:\n",
            ">> Jane Austen.\n",
            "\n",
            "Model response:\n",
            ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
            "-------------------------------------\n"
          ]
        }
      ],
      "source": [
        "#TODO\n",
        "torch.manual_seed(123)\n",
        "for entry in test_data[:3]:\n",
        "  input_text = format_input(entry)\n",
        "  token_ids = generate(\n",
        "  model=model,\n",
        "  idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
        "  max_new_tokens=256,\n",
        "  context_size=BASE_CONFIG[\"context_length\"],\n",
        "  eos_id=50256\n",
        "  )\n",
        "  generated_text = token_ids_to_text(token_ids, tokenizer)\n",
        "  response_text = (\n",
        "  generated_text[len(input_text):]\n",
        "  .replace(\"### Response:\", \"\")\n",
        "  .strip()\n",
        "  )\n",
        "  print(input_text)\n",
        "  print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
        "  print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
        "  print(\"-------------------------------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvV2_Dj4TW--",
        "outputId": "c6a8d346-08d8-47ca-cb75-9d9f36a9b769"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 110/110 [01:15<00:00,  1.46it/s]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
        "  input_text = format_input(entry)\n",
        "  token_ids = generate(\n",
        "  model=model,\n",
        "  idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
        "  max_new_tokens=256,\n",
        "  context_size=BASE_CONFIG[\"context_length\"],\n",
        "  eos_id=50256\n",
        "  )\n",
        "  generated_text = token_ids_to_text(token_ids, tokenizer)\n",
        "  response_text = (\n",
        "  generated_text[len(input_text):]\n",
        "  .replace(\"### Response:\", \"\")\n",
        "  .strip()\n",
        "  )\n",
        "  test_data[i][\"model_response\"] = response_text\n",
        "with open(\"instruction-data-with-response.json\", \"w\") as file:\n",
        "  json.dump(test_data, file, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjPkp9eJT_-A",
        "outputId": "d3297d20-ef21-4a36-97aa-93954c8c9ad8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'instruction': 'Rewrite the sentence using a simile.', 'input': 'The car is very fast.', 'output': 'The car is as fast as lightning.', 'model_response': 'The car is as fast as a bullet.'}\n"
          ]
        }
      ],
      "source": [
        "print(test_data[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_M5jrE6gUMl7",
        "outputId": "e4d3377a-4ada-44ae-f437-5e91191c2202"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved as gpt2-medium355M-sft.pth\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "file_name = f\"{re.sub(r'[ ()]', '', CHOOSE_MODEL) }-sft.pth\"\n",
        "torch.save(model.state_dict(), file_name)\n",
        "print(f\"Model saved as {file_name}\")\n",
        "#model.load_state_dict(torch.load(\"gpt2-medium355M-sft.pth\"))."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RHY2IUnU4tA"
      },
      "source": [
        "# 5 - Evaluation du LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zj7X_BB-U3tz"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
